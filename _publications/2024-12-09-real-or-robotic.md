---
title: "Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue"
authors: "Jonathan Ivey, Shivani Kumar, Jiayu Liu, Hua Shen, Sushrita Rakshit, Rohan Raju, Haotian Zhang, Aparna Ananthasubramaniam, Junghwan Kim, Bowen Yi, **Dustin Wright**, Abraham Israeli, Anders Giovanni MÃ¸ller, Lechen Zhang, David Jurgens"
collection: publications
permalink: /publication/2024-12-09-real-or-robotic
excerpt: 'We show that simulations of real people in dialogue settings are not faithful'
date: 2024-09-12
venue: 'arxiv'
paperurl: 'https://arxiv.org/abs/2409.08330'
bibtex: '@article{ivey2024real,
  title={Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue},
  author={Ivey, Jonathan and Kumar, Shivani and Liu, Jiayu and Shen, Hua and Rakshit, Sushrita and Raju, Rohan and Zhang, Haotian and Ananthasubramaniam, Aparna and Kim, Junghwan and Yi, Bowen and others},
  journal={arXiv preprint arXiv:2409.08330},
  year={2024}
}'
---
Studying and building datasets for dialogue tasks is both expensive and time-consuming due to the need to recruit, train, and collect data from study participants. In response, much recent work has sought to use large language models (LLMs) to simulate both human-human and human-LLM interactions, as they have been shown to generate convincingly human-like text in many settings. However, to what extent do LLM-based simulations \textit{actually} reflect human dialogues? In this work, we answer this question by generating a large-scale dataset of 100,000 paired LLM-LLM and human-LLM dialogues from the WildChat dataset and quantifying how well the LLM simulations align with their human counterparts. Overall, we find relatively low alignment between simulations and human interactions, demonstrating a systematic divergence along the multiple textual properties, including style and content. Further, in comparisons of English, Chinese, and Russian dialogues, we find that models perform similarly. Our results suggest that LLMs generally perform better when the human themself writes in a way that is more similar to the LLM's own style.
[Download paper here](https://arxiv.org/abs/2409.08330)


Recommended bibtex: 

```
@article{ivey2024real,
  title={{Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue}},
  author={Ivey, Jonathan and Kumar, Shivani and Liu, Jiayu and Shen, Hua and Rakshit, Sushrita and Raju, Rohan and Zhang, Haotian and Ananthasubramaniam, Aparna and Kim, Junghwan and Yi, Bowen and others},
  journal={arXiv preprint arXiv:2409.08330},
  year={2024}
}
```
